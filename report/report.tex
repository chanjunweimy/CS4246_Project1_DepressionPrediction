\documentclass{article}
\usepackage{aaai}
\usepackage{fixbib}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{url}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{FB01}{fi}
\graphicspath{ {images/} }
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}


\title{
	CS4246 AI Planning and Decision Making - Project 1 \\
	Depression Prediction
}
\author{
	{\bf Team 01} \\
	Antoine Charles Vincent Garcia - A0159072A\\
	Chan Jun Wei - A0112084U\\
	Chen Tze Cheng - A0112092W\\
	Eric Ewe Yow Choong - A0112204E\\
	Han Liang Wee, Eric - A0065517A\\
	Ho Wei Li - A0094679H\\
}

\begin{document}
 	\maketitle

	\begin{abstract}
	\begin{quote}
	Depression is a debiliatating mental illness that has good prognosis given early detection and treatment. 
	However, detection is difficult with the various factors that raise the entry barriers and decrease the accuracy of a diagnostic test. Research have shown that accurate predictions of emotions can be made with Gaussian Process models. This study explores the novel use Gaussian Process in predicting depression severity using acoustic measures of voice.
	Our work has succesfully shown that Gaussian Process Dot Product trained using MFCC feature set is a good model for depression prediction and can predict PHQ-8 better than other state-of-the-art models at RMSE of 6.34.\\
	\end{quote}
	\end{abstract}
	
	\section{Introduction}
	Depression has a severe, and at times long-term, negative impact on an individual's quality of life. 
	Major depression is 3rd leading cause of disability worldwide with 65 million life years spent living with the disability or lost due to early death \cite{who2004}.
	Depression's annual toll on U.S businesses amounts to about \$80 billion in medical expenditures, lost productivity and suicide. 
	Among the costs, close to \$10 billion accrued in lost workdays each year and more than \$33 billion in other costs accrue from decreased productivity due to symptoms that sap energy, affect work habits, cause problems with concentration, memory, and decision-making \cite{tjcp2015}. \\

	Left unchecked, depression increases risk for morbidity, suicide, decreased cognitive and social functioning, self-neglect, and early death \cite{arcp2009}. 
	Death from suicide is one of the top 10 causes of death, above the death rate for chronic liver disease, Alzheimer's, homicide, arteriosclerosis or hypertension \cite{nvsr2016}. \\

	Despite the severe consequences, depression is one of the most treatable mental illnesses but it is also one of the most under-diagnosed globally. 
	In general health-care, 48.4\% of patients suffering from depression go unrecognized \cite{jama2003}.

	\subsection{Motivation and Objective}
	The Personal Health Questionaire depression scale (PHQ-8) is a self-administered, 8-question diagnostic test for depressive disorders that has proven to be an effective severity measure for depression in large clinical studies \cite{jad2008}. 
	Nevertheless, one of the biggest obstacles to successful diagnosis of depression is the unwillingness of patients to admit their predisposition to depression by seeking help.\\

	People often subscribe to the social stigma that being depressed reflects a weakness in their character, a permanent defect in their personality. 
	This stigma manifests itself particularly in a phenomenon known as social distancing whereby people with mental issues are more isolated from others \cite{tpcrp2011}.  
	People suffering from depression hence tend to be ashamed of their condition and are generally convinced that denying and hiding it from others gives them a better shot at integrating with society and living a normal life \cite{bmb2001}.
	Even if they do seek help, the accuracy of the PHQ-8 or just questionaires and surveys in general are often adversely affected by the Hawthorne Effect, a type of reactivity in which individuals modify or improve an aspect of their behavior in response to their awareness of being observed. \cite{jce2014}.\\

	In the past decade, there have been research successfully correlating emotion with voice production and speech acoustics \cite{uwa2001}. Corollary to that, active research of late into the use of voice acoustics as predictors of clinical depression scores has seen success, proving that it is an effective indicator of depression severity \cite{jov2016}.\\

	In this paper, we investigate the applicability and feasibility of Gaussian Process (GP) models in predicting clinical ratings of depression severity on the PHQ-8 scale with acoustic measures of voice from a sample of patients and compare their performance with current state-of-the-art machine learning models. Some of our preliminary studies have shown that despite consensus among the scientific community that Support Vector Machine (SVM) models have a very high predictive accuracy specifically in speech emotion recognition \cite{Chavhan2010}, GP models have been proven to consistently outperform SVM models on the task of music emotion recognition \cite{MARKOV2013}. Nevertheless, there are no studies on the use of GP in predicting depression severity. The findings of this paper will hopefully open up new frontiers and fuel further research interest on this topic.
	
	\subsection{Future Applications}
	Results from this experiment will reinforce results from similar experiments and make a stronger case for the possibility of lowering the entry barriers of depression diagnostic tests and at the same time, increasing the accuracy of depression diagnosis by abstracting the Hawthorne Effect. 
	Diagnostic tests can be designed in a friendly way that does not require the patient to consciously answer questionaires such as the PHQ-8 or even to have complete awareness of the diagnostic process. 
	By taking into account the Hawthorne Effect and the status quo of the social stigma and working around them, diagnoses can be made easier, faster and more accurately and with that, education and treatment can begin early before the mental condition of the patient deteriorates.
	
	\section{Modelling and Approach}
	Studies have proven that Gaussian Process is a applicable model for emotion prediction in voice acoustics. As an extrapolation of emotion prediction, we posit that GP is also applicable for prediction of depression. \\	
	
	The following premises have to hold true so that the GP model is suitable for depression prediction:
	\begin{enumerate}
		\item Depression prediction is an event-based recognition which provides a single depression estimate over a certain amount of time. \cite{Valstar2016}
		\item The speech signals extracted from different people suffering from depression should share some similarities and thus admissible for prediction with the Gaussian Process models. 
		For example, diminished, prosodic and monotonous speech is often strongly correlated with depression. \cite{Cummins2015}
	\end{enumerate}

	\subsection{Qualitative Advantages}
	GP is exceptionally useful in this application as it's noise tolerance takes into account outliers in our dataset such as recordings with irregular sampling rates. \\

	GP also provides predictions with a clear probabilistic interpretation by also providing an estimate of prediction uncertainty. 
	From the prediction uncertainty, we are able to intelligently supplement more data in aspects with higher uncertainty to improve the GP model. 
	Moreover, we are able to get a sense of the quality of each prediction from the prediction uncertainty. 
	These properties are unique to a GP models and are missing in many other machine learning models.
	In our context, an individual would be able to obtain both the predicted PHQ-8 score and also prediction confidence when using a GP model. 
	Hence, he would be able to get a sense of whether or not to trust the predicted PHQ-8 score and make informed decisions from there.\\
	
	\subsection{Gaussian Process Model} \label{audio_feats}
	In our model, we first analyse the following aspects:
	\begin{enumerate}
		\item \textbf{Audio Feature Sets}	\\
		An audio signature can be uniquely defined by the following feature sets:
		\begin{enumerate}
			\item \textbf{Energy}	\\
			The Energy feature of a sound refers to the loudness of the sound at various timeframes, 
			hence the energy of a sound is directly proportional to the amplitude of the soundwave. 
			The louder the sound, the higher the energy.
		
			\item \textbf{Mel Frequency Cepstral Coefficients (MFCC)} \\
			Mel Frequency Cepstral (MFC) is a representation of short-term power spectrum of a sound, 
			based on a linear cosine transform of a log power spectrum on a nonlinear Mel scale of frequency. 
			The greatest benefit of using MFCC is that the scale approximates the 
			human's auditory system response more closely, hence it allows for a better representation of sound. 
			In order to obtain MFCC, Fourier transform is performed on the sound signals.	
		
			\item \textbf{Magnitude Spectrum} \\
			Magnitude spectrum can be produced by converting the input signal of an audio into frames. 
			Fast Fourier Transform is performed on each frames and this will form the Magnitude Spectrum.
			
			\item \textbf{Zero-Crossing Rate} \\
			Zero crossing rate is the rate of sign-changes along a signal.
		\end{enumerate}
	
	Depression is characterized by a pervasive and persistent low mood and the difficulty in diagnosis 
	lies in detecting the subtle but clear-cut changes in the baseline of a patient's voice \cite{Stratou2015}.
	Given the task and the fact that the baseline accuracy of using MFCC to predict emotions in audio is relatively high, 
	we postulate that MFCC is the most important feature in depression prediction \cite{ElAyadi2011}. 
	Consequently, since we have limited data and large feature dimension, 
	using only the MFCC feature set as the input vector of the model is expected improve the result.
		
		\item \textbf{Kernels}\\
		The similarity measure of all features is known as the kernel and are used to predict the value of an unobserved point from the training data. \\

		The kernels tested are shown below:\\
		The kernels are assumed to be defined on two samples \( x = ( x_{1} x_{2} x_{3} ... x_{n} ) \) and 
		\( x' = ( {x_{1}}' {x_{2}}' {x_{3}}' ... {x_{n}}')\),  
		represented as feature vectors in some input space\\

		\begin{enumerate}
			\item \textbf{Radial Basis Function (RBF)}\\
			The RBF kernel is defined as 
			\begin{equation}\label{eq:kernel_rbf}
				K(x,x') = \exp^{-\frac{||x-x'||^{2}}{2\sigma^{2}}}
			\end{equation}
			\(||x-x'||^{2}\) represents the squared Euclidean distance 
			And \( \sigma > 0 \) can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions 
			as the inputs X (anisotropic variant of the kernel). \\
			It is also known as the squared exponential kernel. 
			This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, 
			and are thus very smooth.
			
			\item \textbf{Matern}\\
			The class of Matern kernels is a generalization of the RBF and the absolute exponential kernel, parameterized 
			by an additional parameter $\nu$ (nu). The smaller the value of $\nu$, the less smooth the approximated function becomes. When $\nu=\infty$, 
			the kernel becomes equivalent to the RBF kernel and when $\nu=0.5$, to the absolute exponential kernel. 
			Important intermediate values are $\nu=1.5$ (once differentiable functions) and $\nu=2.5$ (twice differentiable functions).

			\item \textbf{Automatic Relevance Detection (ARD)}\\
			If we chose the anisotropic variant of the RBF and Matern kernel, then these kernels are also known as ARD kernels.
			For the model, the difference is that each \(\sigma_{i}\), where $i = 1,2,3,...,n$ might be different, 
			depending the importance of the corresponding input features.\\

			ARD is advantageous for the experiment as: 
			\begin{enumerate}
				\item Generalisation performance is potentially improved.
				\item The data would be better explained.
				\item Increase the efficiency of feature extraction for audio.
			\end{enumerate}
			\cite{Cawley2014}
			
			\item \textbf{Dot Product}\\
			The Dot Product kernel is non-stationary and can be obtained from linear regression by putting $N(0,1)$ priors on the coefficients 
			of $x_{d} (d = 1, . . . , D)$ and a prior of $N(0, \sigma_{0}^{2})$ on the bias. 
			The Dot Product kernel is invariant to a rotation of the coordinates about the origin, but not translations. 
			It is parameterized by a parameter $\sigma_{0}^{2}$. For $\sigma_{0}^{2} = 0$, 
			the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by
			\begin{equation}\label{eq:kernel_dp}
				K(x,x') = \sigma_{0}^{2} + x \cdot x'  
			\end{equation}
		\end{enumerate}

		While Matern is a very generalized kernel, both isotropic and ARD variant of the Matern kernel are selected for our model. 
		On the other hand, as dot product kernel is a very efficient and simple kernel, it is tested as well.
	\end{enumerate}

	Without doing feature selections, the feature dimensions would be huge. 
	As a result, it is likely to lead to overfitting and poor generalisation of the model \cite{Cawley2014}. 
	Thus, to increase the effectiveness of the GP model, we would apply feature selection to the data first.

	\subsection{State-of-art Machine Learning Models}
	The following machine learning models are used:
	\begin{enumerate}
		\item \textbf{K-Nearest Neighbors} \\
		The K-Nearest Neighbors is a non-parametric method for classification and regression. 
		The training examples are vectors in a multidimensional feature space, each with a class label. 
		The data will be classified into the class with most number of occurrence within the defined k radius.
	
		\item \textbf{Support Vector Machines (SVM)} \\
		SVM, with the help of the libsvm, is a type of linear classiﬁers that aims at ﬁnding 
		a unique solution in the form of an optimal hyperplane which is deﬁned as the one that maximizes the margins between the two classes.

		\item \textbf{Random Forest Regressor} \\
		Random Forest is an ensemble of decision trees, whereas a decision tree tries to separate the data into different leaf nodes 
		where the data points in each node have certain similarity. Each decision tree will predict a value and the values will be averaged to be the result.
	
		\item \textbf{AdaBoost} \\
		AdaBoost is the short form of Adaptive Boost which is sensitive to noisy data and outliers. 
		AdaBoost first find out the classifier with the least errors, adding the weight to the outliers, then find out another classifier with least errors again.
		A final classifier will be combined and indicate the class of data.
	
		\item \textbf{Naive Bayes} \\ 
		Naive Bayes is a prediction algorithm that uses Bayes rule. 
		All naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. 
		The possibilities is represented by the number of times the particular event occurs in the dataset over the total number of events. 
	\end{enumerate}

	\section{Evaluation}
	In order to test our proposed GP models, we conducted tests on data obtained from Audio/Visual Emotion Challenge and Workshop (AVEC 2016) \cite{avec2016}. 
	The goal of AVEC is to weigh-in on the various approaches used to recognize emotions under unambiguous conditions. 
	AVEC 2016 provided 2 pieces of data as input: visual and auditory data from each of the participants. 
	However, we would be reducing the scope of the experiment, limiting the experiment to only the auditory data. 
	Two Sub-Challenges were lised in AVEC 2016. 
	We are only interested in the Depression Classification Sub-Challenge, which requires participants to classify inputs by the PHQ-8 score. 
	In this experiment, we would be using the audio data along with their corresponding PHQ-8 scores to test our assumptions and confirm our hypothesis.

	\subsection{Data}
	\begin{figure}[h]
	\center
 	\includegraphics[width=0.5\textwidth]{histogram_phq8}
	\caption{Histogram of the PHQ-8 scores}
	\label{histogram_phq8}
	\end{figure}
	
	The depression data used in AVEC 2016 was obtained from the benchmarking database, Distress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ). 
	Data collected from DAIC-WOZ include raw audio and video recordings and the corresponsing PHQ-8 score (from 0 to 24) \cite{jad2008}. Hence, we would 
	need to pre-process the auditory data before we use it in our experiment. The pre-processing is briefly discussed in the section below.
	The distribution of the depression severity scores in the dataset is given in Figure \ref{histogram_phq8}. 
	The data provided are split into 2 sets: training and development.
	An overview of the data is given in Table \ref{summary_table}.

 	\begin{table}[h]
 		\begin{center}
  			\begin{tabular}{ | r | c | c | c | }
    			\hline
			 		& \bfseries Training	& \bfseries Development 	& \bfseries All \\ \hline
			 $n$		& 95 			& 31 				& 126 \\ \hline
			 $\mu$	& 6.326 		& 7.548			& 6.626 \\ \hline
			 $\sigma$	& 5.597 		& 6.690 			& 5.909 \\ \hline
			 \end{tabular}
		\end{center}
 	\caption{Summary of Datasets provided}
 	\label{summary_table}
 	\end{table}

	\subsection{Pre-processed data}
	Since the focus of this paper is the prediction of the PHQ-8 score, we will not describe the pre-processing step in detail.
	We used standard signal processing techniques to extract the 4 audio feature sets (Energy, MFCC, Magnitude Spectrum, Zero-crossing) as presented in the Modelling 
	and Approach section.
	Each audio feature set comprises of several individual features and the breakdown of the actual number of feature columns is summarized in Table \ref{no_features}.

 	\begin{table}[h]
 		\begin{center}
  			\begin{tabular}{ | r | c | }
    			\hline
			 \bfseries Audio Feature Sets 	& \bfseries Number of features \\ \hline
			 Magnitude Spectrum		& 512 \\ \hline
			 MFCC 				& 12 \\ \hline
			 Energy 				& 1 \\ \hline
			 Zero-Crossing Rate 		& 1 \\ \hline
			 \bfseries Total			& \bfseries 526 \\ \hline
			 \end{tabular}
		\end{center}
 	\caption{Number of features extracted}
 	\label{no_features}
 	\end{table}

 	\subsection{Measure of Accuracy}
	AVEC 2016 provided a baseline classifier that consistently predicts the PHQ-8 score with $\text{RMSE}=6.7418$ \cite{avec2016}. 
	In order to provide a meaningful and consistent comparison to the baseline provided, we used the same Root Mean Square Deviation Error (RMSE) to measure the 
	error rate on both Training and Development datasets. 
	RMSE (Equation \ref{eq:rmse}) is a commonly used in the machine learning community to measure the differences between the values predicted by a model 
	and the ground truth \cite{Dhanani:EECS-2014-131}. 
	\begin{equation}\label{eq:rmse}
  	\text{RMSE} = \sqrt{\frac{\sum_{t=1}^n (\hat y_t - y_t)^2}{n}}
 	\end{equation} 

	\subsection{Feature Selection}
	Feature selection is the process of selecting a subset of relevant features including variables or predictors to be used in a model for machine learning. 
	The purpose of feature selection is to reduce the complexity of a model to more easily be interpreted. 
	The benefit is three-fold: improving the prediction performance of the predictors, providing faster and most cost-effective predictors, 
	and providing a better understanding of the underlying process that generated the data \cite{Guyon2003}.\\
	
	Since we have more features than data points, it tends to lead to overfitting \cite{Smith2011}. 
	Therefore feature selection is first performed on the data before applying machine learning. 
	The feature selection algorithms used are popular and are taken from scikit-feature, a feature selection library \cite{li2016feature}: CIFE \cite{Lin2006}, Relief 	
	\cite{Rob2003}, CFS \cite{HALLHALL}. 
	We will not go into detail as feature selection is not the main focus of the report.
	
	\subsection{Experimental Setup}
	We compared the proposed GP models against state-of-the-art machine learning models as mentioned in the previous section. 
	For the ease of testing, all implementations of the algorithms except for GP ARD come from the popular machine learning library, Scikit Learn \cite{scikit-learn}. 
	We used the implementation of GP ARD from GPy, a Gaussian Processes framework in Python \cite{gpy2014}.
	The hyper-parameters are either determined by the defaults used in either libraries or some reasonable defaults were used.
	Each machine learning model is trained against the training set and thereafter tested against the development set using RMSE as the error metric. 
	The entire experimental process is shown in Figure \ref{process}. \\
 
 	\begin{comment}
	\begin{table}[h]
  		\begin{center}
   			\begin{tabular}{ | r | c |}
	    		\hline
			Algorithm & Hyper-parameters \\ \hline\hline
			K-Nearest Neighbors        & x \\ \hline
			SVM - Linear               & x \\ \hline
			SVM - RBF                  & x \\ \hline
			Decision Tree              & x \\ \hline
			Random Forest              & x \\ \hline
			AdaBoost                   & x \\ \hline
			Naive Bayes                & x \\ \hline
			GP ARD  	           & x \\ \hline
			GP Isotropic Matern        & x \\ \hline
			GP Dot Product 	           & x \\ \hline
			\end{tabular}
		\end{center}
		\caption{List of Machine Learning Algorithms with their corresponding hyper-parameters}
		\label{list_mls}
	\end{table}
 	\end{comment}
 	
	\begin{figure}[h]
 		\begin{center}
		\includegraphics[width=0.48\textwidth]{process} 
  		\end{center}
  		\caption{Experimental process}
  		\label{process} 
 	\end{figure}
 	\begin{comment}
	@startuml
	digraph g {
		graph [rankdir=LR];
	 	ML,RMSE[shape=square];
		Model[shape=circle];
		ap[shape=rect label="Audio Processing"];
		Train_AudioData,Dev_AudioData[shape=egg];
		Train_AudioData -> ap;
		ap -> Train_X;
		ap -> Train_y;
		ap -> Dev_X;
		Dev_AudioData -> ap;
		ap -> Dev_y;
		Train_X -> ML;
		Train_y -> ML;
		ML -> Model
		Dev_X -> Model
		Model -> RMSE[label=Prediction]
		Dev_y -> RMSE[label=Actual]
	}
	@enduml
 	\end{comment}

	\subsection{Results}
	We first ran the experiment across the dataset using all 526 features, without feature selection. 
	As we would expect \cite{Cawley2014}, the results are unacceptable as the ratio of the number of features to the number of data points is too high,
	resulting in possible overfitting. 
	The results of the initial experiment is illustrated in Figure \ref{results_all}. 
	We would expect the GP ARD would be able to theoritcally extract relevant features and improve prediction.
	However, we have observed experimentally that GP ARD performs poorly, along with other GPs. \\

	\begin{figure}[h]
 		\begin{center}
		\includegraphics[width=0.5\textwidth]{results_all} 
  		\end{center}
  		\caption{Results across all features}
  		\label{results_all}
 	\end{figure}
	
	We repeated the experiment with feature selection and ran each of the feature subset gathered from the feature selection algorithms against each of the machine 
	learning algorithms. 
	We observed that Relief, CIFE and CFS selected a large number of MFCC features. 
	The number of features in each feature subset is shown in Table \ref{feat_subset}. 
	This confirms our assumption that MFCC gives the best predictive power in PHQ-8 depression severity prediction. 
	Hence, we also ran the experiment using only MFCC features. 
	The best results across all feature subsets are shown in Figure \ref{results_best} and in Table \ref{rmse_results}. \\

 	\begin{table}[h]
 		\begin{center}
  			\begin{tabular}{ | r | c | }
    			\hline
			 \bfseries Feature Selection 	&\bfseries Number of features \\ \hline
			 MFCC           			& 12 \\ \hline
			 CIFE        				& 3 \\ \hline
			 Relief 				& 23 \\ \hline
			 CFS 					& 6 \\ \hline
			 All 					& 526 \\ \hline
			 \end{tabular}
		\end{center}
 	\caption{Feature subsets}
 	\label{feat_subset}
 	\end{table}

	\begin{figure}[h]
 		\begin{center}
		\includegraphics[width=0.5\textwidth]{results_best} 
  		\end{center}
  		\caption{Best Results across all feature subsets}
  		\label{results_best}
 	\end{figure}

	\begin{table}[h!]
		\begin{center}
			\begin{tabular}{ | r | c | c | c | }
			\hline
			\multirow{2}{*}{\bfseries Algorithm}	& \multirow{2}{*}{\bfseries Subset}	& \multicolumn{2}{c|}{\bfseries RMSE} \\\cline{3-4}
									&						& \bfseries Train 	& \bfseries Dev \\ \hline
			\bfseries GP Dot Product  	& \bfseries MFCC  & \bfseries 5.03 & \bfseries 6.34 \\ \hline
			AdaBoost              				& Relief					& 3.55 		& 6.52 \\ \hline
			K-Nearest Neighbors   			& CFS 					& 3.75 		& 6.53 \\ \hline
			SVM - Linear          				& MFCC  					& 5.29 		& 6.63 \\ \hline
			Random Forest         			& CFS   					& 5.61 		& 6.75 \\ \hline
			Decision Tree         				& MFCC  					& 5.60 		& 6.80 \\ \hline
			SVM - RBF             				& CIFE  					& 4.91 		& 6.91 \\ \hline
			GP Isotropic Matern   			& CFS   					& 0.00 		& 7.18 \\ \hline 
			Naive Bayes           				& Relief					& 6.87 		& 7.59 \\ \hline
			GP ARD                				& All   						& 3.72 		& 10.09 \\ \hline

			\end{tabular}
		\end{center}
		\caption{RMSE Results}
		\label{rmse_results}
	\end{table}
	
	As expected, the models perform better with the MFCC feature set. 
	Unexpectedly, the simple GP dot product model, trained with 12 features and 95 data points, outperforms all other machine learning models in our tests. 
	Our results also confirms the initial assumption that MFCC is an appropriate feature set to be used in emotion and therefore depression prediction and that GP is 
	applicable and feasible in predicting PHQ-8 scores.

	\section{Conclusion}	
	Our work has succesfully shown that GP is a good model for this problem and can predict PHQ-8 better than state-of-the-art machine learning models. 
	In addition to being on par or better at prediction, GP can inherently provide an estimate of prediction uncertainty. 
	This allows the user to gauge the model's confidence of the prediction, and to make more informed decisions based on both the prediction and its uncertainty. 
	We can also intelligently supplement more data to our training set based on the prediction uncertaintly. 
	Therefore, after considering both results and GP's advantages, we conclude the GP Dot Product trained using MFCC feature set is a good model for 
	depression prediction.
	
	\section{Further Work}
	For this experiment, we only used machine learning algorithms with their default parameters. 
	An aspect that deserves further exploration is to perform automatic hyper-parameter optimization
	across all the machine learning algorithms to fine-tune each model's performance. 
	In particular, we can try Hyperopt-sklearn \cite{Komer2014HyperoptsklearnAH} or GP based hyper-parameter tuner. 
	We opine that with hyper-parameter tuning, we can predict PHQ-8 scores better and can have a more objective comparison of the different learning algorithms.
	
	\section{Contributions}
	\begin{itemize}
		\item \textbf{Antoine Charles Vincent Garcia}: 
		Scripting the program, setting up machine learning libraries and running tests.
		\item \textbf{Chan Jun Wei}: 
		Project technicalities such as problem formulation and modelling, mathematics and experiment planning.
		\item \textbf{Chen Tze Cheng}: 
		Project technicalities such as problem formulation and modelling, mathematics and experiment planning.
		\item \textbf{Eric Ewe Yow Choong}: 
		Formatting of the report, resolution of LaTeX issues and keeping track of requirements
		\item \textbf{Han Liang Wee, Eric}: 
		Scripting the program, setting up machine learning libraries and running tests.
		\item \textbf{Ho Wei Li}: 
		Background research, writing up of the abstract and introduction section, vetting the flow and editing and standardization of the entire report. \\
	\end{itemize}
	
	\bibliographystyle{aaai}
	{\scriptsize \bibliography{references}}

\end{document}
